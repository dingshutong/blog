{"componentChunkName":"component---src-templates-post-template-js","path":"/posts/structuring-ML-projects","result":{"data":{"markdownRemark":{"id":"e2853977-3a58-503b-bc4b-27c8339a5afa","html":"<h2 id=\"why-ml-strategy\" style=\"position:relative;\"><a href=\"#why-ml-strategy\" aria-label=\"why ml strategy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Why ML strategy</h2>\n<p>In order to improve your machine learning model, you might need to try out many different ideas. If you have a good ML strategy, it allows your to have quick and effective ways to figure out which of all of these ideas and maybe even other ideas, are worth pursuing and which ones you can safely discard. </p>\n<blockquote>\n<p>A number of strategies, that is, ways of analyzing a machine learning problem that will point   you in the direction of the most promising things to try. </p>\n</blockquote>\n<h2 id=\"orthogonalization-process\" style=\"position:relative;\"><a href=\"#orthogonalization-process\" aria-label=\"orthogonalization process permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Orthogonalization Process</h2>\n<p>Orthogonalization allows you to split and to separate different tuning <em>knobs</em> (procedures) to check its effect individually. </p>\n<h3 id=\"chain-of-assumptions-in-ml\" style=\"position:relative;\"><a href=\"#chain-of-assumptions-in-ml\" aria-label=\"chain of assumptions in ml permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Chain of assumptions in ML</h3>\n<p>Fit the <strong>training set</strong> well on cost function? (Bigger network, Adam …)</p>\n<p>-></p>\n<p>Fit the <strong>dev set</strong> well on cost function? (Regularization, bigger training set)</p>\n<p>-></p>\n<p>Fit the <strong>test set</strong> well on cost function? (Bigger dev set)</p>\n<p>-></p>\n<p>Perform well in real world application (change dev set or cost function)</p>\n<h2 id=\"setting-up-your-goals\" style=\"position:relative;\"><a href=\"#setting-up-your-goals\" aria-label=\"setting up your goals permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Setting up your goals</h2>\n<p>Usually it is more effective to use a <strong>single number evaluation metric</strong> when comparing across different models and algorithms. If the evaluation metrics can be combined by some sort of averaging, we could use their harmonic mean as a single measure.</p>\n<p>However, it’s not always easy to combine all the things you care about into a single row number evaluation metric. In those cases it is sometimes useful to set up <strong>satisficing as well as optimizing metric</strong>. For example, </p>\n<table>\n<thead>\n<tr>\n<th>Algorithm</th>\n<th>Accuracy</th>\n<th>Running time</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>A</td>\n<td>93%</td>\n<td>80ms</td>\n</tr>\n<tr>\n<td>B</td>\n<td>94%</td>\n<td>82ms</td>\n</tr>\n<tr>\n<td>C</td>\n<td>96%</td>\n<td>1800ms</td>\n</tr>\n</tbody>\n</table>\n<p>One way to create a single metric is to create a cost measure such as the overall cost is accuracy minus 0.5 times running time. Or a more easier way is to optimize the accuracy while satisficing at certain running speed. That is, for example to maximize Accuracy subject to Running time &#x3C;= 100ms. </p>\n<p>So if you have N metrics to look, you can choose the most important one you want to optimze, and the rest N-1 metrics as the subject-to satisficer. </p>\n<h2 id=\"traindevtest-distributions\" style=\"position:relative;\"><a href=\"#traindevtest-distributions\" aria-label=\"traindevtest distributions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Train/dev/test distributions</h2>\n<p><strong>dev</strong> set is also called the development set, or sometimes it is called hold-out cross validation set. Ideally, the dev set and the test set should come from the same distribution.\nPull all your data and then randomly shuffle them and split them into dev/test. </p>\n<p>Choose a dev set and test set to reflect data you expect to get in the future and consider important to do well on.</p>\n<p>Set your test set to be big enough to give high confidence in the overall performance of your system. For some applications, maybe you don’t need a high confidence in the overall performance of your final system. Maybe all you need is a train and dev set, not having a test set might be okay. </p>\n<p>In the modern machine learning exercises, the trend has been to use more data for training and less for dev and test, especially when you have a very large data sets. Say you have over 1 million samples, to split them: we could have 98% train/ 1% dev/ 1% test. </p>\n<h2 id=\"when-to-change-devtest-sets-and-metrics\" style=\"position:relative;\"><a href=\"#when-to-change-devtest-sets-and-metrics\" aria-label=\"when to change devtest sets and metrics permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>When to change dev/test sets and metrics</h2>\n<p>Sometimes partway through a project you might realize you put your target in the wrong place. In that case you should move your target. </p>\n<p>For example, if it is doing well on your metric + dev/test sets does not correspond to doing well on your application, change your metric and/or dev/test sets.</p>\n<p>If your current metric and data you are evaluating on doesn’t correspond to doing well on what you actually care about, then change your metrics and/or your dev/test set to better capture what you need your algorithm to actually do well on.</p>","fields":{"slug":"/posts/structuring-ML-projects","tagSlugs":["/tag/machine-learning/"]},"frontmatter":{"date":"2021-02-09T22:12","description":"Notes taken from the AI course by Andrew Ng.","tags":["Machine Learning"],"title":"Structuring Machine Learning Projects","socialImage":{"publicURL":"/tblog/static/3e20438298edd3a3fa746766d803f379/gutenberg.jpg"}}}},"pageContext":{"slug":"/posts/structuring-ML-projects"}},"staticQueryHashes":["251939775","401334301","825871152"]}